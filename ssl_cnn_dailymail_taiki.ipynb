{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f733ee56",
   "metadata": {},
   "source": [
    "# Semi Supervised Learning Method \n",
    "### By Taiki Papandreou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885081b",
   "metadata": {},
   "source": [
    "## Quick Recap\n",
    "Semi Supervised learning model is trained on both labeled and unlabled data. Since we manually labled our data in week 2. We can implement this technique in week 3. <br>\n",
    "The goal of this model is to get a better result than lbl2vec. <br>\n",
    "Source: https://machinelearningmastery.com/semi-supervised-learning-with-label-propagation/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ad0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import datasets\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import itertools\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.semi_supervised import LabelPropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0b900",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e20a5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n",
       "      <td>Harry Potter star Daniel Radcliffe gets £20M f...</td>\n",
       "      <td>42c027e4ff9730fbb3de84c1af0d2c506e41c3e4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Editor's note: In our Behind the Scenes series...</td>\n",
       "      <td>Mentally ill inmates in Miami are housed on th...</td>\n",
       "      <td>ee8871b15c50d0db17b0179a6d2beab35065f1e9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...</td>\n",
       "      <td>NEW: \"I thought I was going to die,\" driver sa...</td>\n",
       "      <td>06352019a19ae31e527f37f7571c6dd7f0c5da37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (CNN) -- Doctors removed five small...</td>\n",
       "      <td>Five small polyps found during procedure; \"non...</td>\n",
       "      <td>24521a2abb2e1f5e34e6824e0f9e56904a2b0e88</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)  -- The National Football League has ind...</td>\n",
       "      <td>NEW: NFL chief, Atlanta Falcons owner critical...</td>\n",
       "      <td>7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  LONDON, England (Reuters) -- Harry Potter star...   \n",
       "1  Editor's note: In our Behind the Scenes series...   \n",
       "2  MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...   \n",
       "3  WASHINGTON (CNN) -- Doctors removed five small...   \n",
       "4  (CNN)  -- The National Football League has ind...   \n",
       "\n",
       "                                          highlights  \\\n",
       "0  Harry Potter star Daniel Radcliffe gets £20M f...   \n",
       "1  Mentally ill inmates in Miami are housed on th...   \n",
       "2  NEW: \"I thought I was going to die,\" driver sa...   \n",
       "3  Five small polyps found during procedure; \"non...   \n",
       "4  NEW: NFL chief, Atlanta Falcons owner critical...   \n",
       "\n",
       "                                         id  label  \n",
       "0  42c027e4ff9730fbb3de84c1af0d2c506e41c3e4    0.0  \n",
       "1  ee8871b15c50d0db17b0179a6d2beab35065f1e9    0.0  \n",
       "2  06352019a19ae31e527f37f7571c6dd7f0c5da37    1.0  \n",
       "3  24521a2abb2e1f5e34e6824e0f9e56904a2b0e88    0.0  \n",
       "4  7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a    0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('0-10000-labeled.csv')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb05306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                              Retired Adm. Dennis Blair confirmed by unanimous consent .\\nConfirmation comes after previous director Michael McConnell resigned .\\nEarlier this month, President Obama nominated Blair as chief of intelligence . 0.0\n",
      "                     FBI looking for financial impropriety after man's clients talked about money loss .\\nPolice say William Parente killed wife, two daughters in hotel room .\\nFamily ID'd as William and Betty Parente, Stephanie, 19, Catherine, 11 .\\nPolice say Parente, an attorney, fatally cut himself . 0.0\n",
      "8-year-old girl sexually assaulted by fellow Liberia natives, police say .\\nDuring Liberia's civil war, rape was used as a weapon by soldiers .\\nU.N. report: 60 to 70 percent of Liberian women were assault victims .\\nJohnson-Sirleaf, first elected female leader in Africa, makes stopping rape a priority . 0.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect some articles with label\n",
    "check0 = df[['highlights', 'label']]\n",
    "n = 3\n",
    "check1 = check0.sample(n)\n",
    "pd.options.display.max_colwidth = 300\n",
    "print(check1.to_string(index=False, header=False))\n",
    "\n",
    "# It seems label 0 is working\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460172a",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c980f964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n",
      "Index(['highlights', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "# We only use highlights in this notebook since it gives enough information on articles\n",
    "df1 = check0\n",
    "print(df1.shape)\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ebbbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highlights</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skier Raphael Beghi captured fall via a helmet-mounted camera .\\nAs he sped down the hill, he lost control of his skis and they flew off .\\nHe quickly crashed to the ground and skidded to a stop in Serre Chevalier .</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two women were arrested for 'intruding' during the Australian Open Final .\\nThey ran onto the court to protest the poor living conditions and treatment of refugees detained on Manus Island immigration detention facility .\\nNovak Djokovic went on to triumph over Andy Murray in the Men's Final .\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                    highlights  \\\n",
       "0                                                                                      Skier Raphael Beghi captured fall via a helmet-mounted camera .\\nAs he sped down the hill, he lost control of his skis and they flew off .\\nHe quickly crashed to the ground and skidded to a stop in Serre Chevalier .   \n",
       "1  Two women were arrested for 'intruding' during the Australian Open Final .\\nThey ran onto the court to protest the poor living conditions and treatment of refugees detained on Manus Island immigration detention facility .\\nNovak Djokovic went on to triumph over Andy Murray in the Men's Final .\\n...   \n",
       "\n",
       "   label  \n",
       "0    NaN  \n",
       "1    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with 10000 unlabeled data\n",
    "# load that data\n",
    "df2 = pd.read_csv('277113-287113-unlabeled.csv')\n",
    "df2 = df2[['highlights', 'label']]\n",
    "df2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122f9214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2)\n",
      "Index(['highlights', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# merge them together\n",
    "frames = [df1, df2]\n",
    "data = pd.concat(frames, ignore_index=True)\n",
    "# The result should have ['highlights','label'] and has 20k records\n",
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b7fb07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 1.45 s, total: 1min 19s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# We need to have a vector representation of highlights\n",
    "# In this project we only look at words and not grammar\n",
    "# So using other text representation might improve the performance\n",
    "\n",
    "###########################################################################\n",
    "\n",
    "# We will only look at nouns since those words give semantics\n",
    "# function to test if something is a noun\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "# lemmatizer for later\n",
    "Lem = WordNetLemmatizer()\n",
    "for i in range(len(data)):\n",
    "    # extract only nouns from highlights\n",
    "    lines = data['highlights'][i]\n",
    "    # tokenize highlights\n",
    "    tokenized = nltk.word_tokenize(lines)\n",
    "    nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n",
    "    # make them lowercase\n",
    "    nouns = [noun.lower() for noun in nouns]\n",
    "    # lemmatization to erase prural etc\n",
    "    nouns = [Lem.lemmatize(noun) for noun in nouns]\n",
    "    # update \n",
    "    data.at[i,'highlights']= nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d299f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset contains  34725 nouns.\n"
     ]
    }
   ],
   "source": [
    "# check how many unique words we have\n",
    "words = list(itertools.chain(data['highlights']))\n",
    "merged = list(itertools.chain(*words))\n",
    "# remove all duplicates now we defined vocabulary (noun only) of our data\n",
    "vocab = set(merged)\n",
    "print(\"This dataset contains \", len(vocab), \"nouns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45dd81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 31676)\n"
     ]
    }
   ],
   "source": [
    "sentences = [' '.join(list) for list in data['highlights']]\n",
    "vectorizer = TfidfVectorizer(norm = False, smooth_idf = False)\n",
    "sentence_vectors = vectorizer.fit_transform(sentences)\n",
    "print(sentence_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1b904d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.99 s, sys: 709 ms, total: 3.7 s\n",
      "Wall time: 3.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = [sentence_vectors[i].toarray()[0] for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e6aa742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[ 0.          4.58632287  4.75930192  4.82126864  4.9633163   5.63562939\n",
      "  5.92675381  6.0359531   6.23065872  6.47267075  6.57275421  6.99146455\n",
      "  7.46950035  8.19543735 15.00458034 17.91515481]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "print(type(X))\n",
    "print(np.unique(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e06fb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1. nan]\n",
      "[ 0.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# because it cannot process NaN I set them to -1\n",
    "print(data['label'].unique())\n",
    "data['label'] = data['label'].replace(np.NaN, -1)\n",
    "print(data['label'].unique())\n",
    "y = np.array(list(data['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cc3b27",
   "metadata": {},
   "source": [
    "# Label Propagation Algorithm\n",
    "\n",
    "Label Propagation is a semi-supervised learning algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "332d9b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tppl/opt/miniconda3/lib/python3.8/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Now that we have our data in a good format we can start with label propagation algorithm\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=1, stratify=y)\n",
    "# split train into labeled and unlabeled\n",
    "X_train_lab, X_test_unlab, y_train_lab, y_test_unlab = train_test_split(X_train, y_train, test_size=0.50, random_state=1, stratify=y_train)\n",
    "# create the training dataset input\n",
    "X_train_mixed = concatenate((X_train_lab, X_test_unlab))\n",
    "y_train_mixed = concatenate((y_train_lab, y_test_unlab))\n",
    "# define model\n",
    "model = LabelPropagation()\n",
    "# fit model on training dataset\n",
    "model.fit(X_train_mixed, y_train_mixed)\n",
    "# make predictions on hold out test set\n",
    "yhat = model.predict(X_test)\n",
    "# calculate score for test set\n",
    "score = accuracy_score(y_test, yhat)\n",
    "# summarize score\n",
    "print('Accuracy: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959d01f",
   "metadata": {},
   "source": [
    "It performs a little bit better than lbl2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d90f0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soldier',\n",
       " 'battle',\n",
       " 'islamic',\n",
       " 'insurgent',\n",
       " 'people',\n",
       " 'body',\n",
       " 'hand',\n",
       " 'foot',\n",
       " 'wire',\n",
       " 'sheet',\n",
       " 'plastic',\n",
       " 'incident',\n",
       " 'dragging',\n",
       " 'u.s.',\n",
       " 'soldier',\n",
       " 'street',\n",
       " 'mogadishu',\n",
       " 'washington',\n",
       " 'somalia',\n",
       " 'haven',\n",
       " 'terrorist']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['highlights'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2924e",
   "metadata": {},
   "source": [
    "## How to improve the accuracy\n",
    "- better labeled dataset (we didn't make criteria list to label our data => subjective and vague label 1)\n",
    "- better way to represent text (Word2Vec?)\n",
    "- different models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc779b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
