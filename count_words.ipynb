{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy problem to count all words in the dataset in order to test reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import nltk\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deze cel downloadet de dataset\n",
    "# hij gebruikt het script cnn_dailymail.py van huggingface:\n",
    "# https://huggingface.co/datasets/cnn_dailymail/tree/main\n",
    "# dit kan wel iets van 10 minuten duren, ga maar wat koffie halen\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail.py\", \"3.0.0\", split=\"train\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print de features en het aantal datapunten in de dataset\n",
    "print(dataset.features)\n",
    "print(dataset.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methoden om de data te pre-processen\n",
    "en_stemmer = EnglishStemmer() # stemmer voor engelse woorden\n",
    "nltk.download('stopwords') # stopwoorden die niet veel waarde toevoegen\n",
    "stop_words = set(stopwords.words('english'))\n",
    "alph_string_pattern = re.compile(\"[a-zA-Z]\") # filtert 'woorden' die niet beginnen met een letter, zoals interpunctietokens\n",
    "\n",
    "\n",
    "def word_counter_text(text: str, stem=False, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Neemt als input een string tekst\n",
    "    Returnt een Counter object die alle woorden uit de tekst telt\n",
    "    \"\"\"\n",
    "    \n",
    "    # splits de tekst op in een lijst van woorden\n",
    "    sents = nltk.tokenize.sent_tokenize(text)\n",
    "    words = [nltk.word_tokenize(sent) for sent in sents]\n",
    "    flatten_words = list(itertools.chain(*words))\n",
    "    \n",
    "    # woorden stemmen of alleen maar hoofdletters weghalen\n",
    "    if stem:\n",
    "        flatten_lower_words = [en_stemmer.stem(str) for str in flatten_words]\n",
    "    else:\n",
    "        flatten_lower_words = [str.lower() for str in flatten_words]\n",
    "    \n",
    "    # stopwoorden weghalen\n",
    "    if remove_stopwords:\n",
    "        flatten_lower_words = [str for str in flatten_lower_words if str not in stop_words]\n",
    "        \n",
    "    # tokens die niet beginnen met een letter weghalen\n",
    "    flatten_lower_words = [str for str in flatten_lower_words if alph_string_pattern.match(str)]\n",
    "    \n",
    "    return Counter(flatten_lower_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = dataset['article']\n",
    "\n",
    "words = Counter() # Counter object dat alle woorden telt\n",
    "for i in tqdm(range(2000)): # kijkt alleen naar de eerste 2000 artikelen, anders duurt het een half uur\n",
    "    words += word_counter_text(texts[i], stem=True, remove_stopwords=True) # tel de Counters bij elkaar op voor elk artikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words.most_common(50))\n",
    "print(len(words.items()), 'verschillende woorden')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
